---
layout: post
category: 数据运维
title:  "hadoop搭建"
tag: [hadoop]
excerpt: 平台搭建。
---

## 版本信息

hadoop	2.5.0

## 集群规划

| | PC01 | PC02 | PC03 |
|:-:|:-:|:-:|:-:|
| NameNode | √ | √ | |
| ZKFC | √ | √ | |
| ResourceManager | | | √ |
| DataNode | √ | √ | √ |
| JournalNode | √ | √ | √ |
| NodeManager | √ | √ | √ |
| ZooKeeper | √ | √ | √ |

## 各组件功能

- **DataNode**: 用来执行具体的存储文件块  
- **DFSZKFailoverController**: Hadoop-2.7.0中HDFS NameNode HA实现的中心组件, 它负责整体的故障转移控制  
- **JournalNode**: 两个NameNode为了数据同步, 会通过一组称作JournalNodes的独立进程进行相互通信。  
- **NameNode**: 保存整个文件系统的名字空间和文件数据块的地址映射  
- **NodeManager**: YARN中单个节点的代理, 它管理Hadoop集群中单个计算节点, 功能包含与ResourceManager保持通信, 管理Container的生命周期、监控每一个Container的资源使用(内存、CPU等）情况、追踪节点健康状况、管理日志和不同应用程序用到的附属服务等。它须要与应用程序的ApplicationMaster和集群管理者ResourceManager交互;它从ApplicationMaster上接收有关Container的命令并执行(比方启动、停止Contaner);向ResourceManager汇报各个Container执行状态和节点健康状况, 并领取有关Container的命令（比方清理Container）。  
- **QuorumPeerMain**: zookeeper集群的启动入口类, 是用来加载配置启动QuorumPeer线程的。  
- **ResourceManager**: 负责集群中所有资源的统一管理和分配, 它接收来自各个节点（NodeManager）的资源汇报信息, 并把这些信息按照一定的策略分配给各个应用程序（实际上是ApplicationManager）。  
- **ZKFC**:

## 文件本地路径

| | 数据路径 | 日志路径 |
|:-:|:-:|:-:|
| HDFS临时 | /data/hadoop/hdfs/tmp | /data/hadoop/hdfs/log |
| NameNode | /data/hadoop/hdfs/nn | /data/hadoop/hdfs/log |
| DataNode | /data/hadoop/hdfs/dn | /data/hadoop/hdfs/log |
| JournalNode | /data/hadoop/hdfs/jn | /data/hadoop/hdfs/log |

## 平台搭建

### 主机准备 centos6

```shell
vim /etc/hosts
  192.168.1.1   bigdata-01
  192.168.1.2   bigdata-02
  192.168.1.3   bigdata-03
```

### 关闭防火墙和SELINUX

```shell
setenforce 0
sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config
grep SELINUX=disabled /etc/selinux/config
# centos6
service iptables stop（关闭防火墙）
chkconfig iptables off（开机不自启动）
# centos7
systemctl disable firewalld.service
systemctl stop firewalld.service
systemctl status firewalld.service
```

### 免密钥登录（这个一定要, 不然你启动的时候, 老是要让你输入各种密码）

```shell
ssh-keygen -t rsa
ssh-copy-id bigdata-01 ; ssh-copy-id bigdata-02 ; ssh-copy-id bigdata-03
```

### 修改文件句柄数

```shell
vim /etc/security/limits.conf
#---------custom-----------------------
#
*           soft   nofile       240000
*           hard   nofile       655350
*           soft   nproc        240000
*           hard   nproc        655350
#-----------end-----------------------
source /etc/security/limits.conf
ulimit -n
24000
```

### ntp服务器同步时间

[链接地址](/posts/2017/11/03/ntp时间同步.html)

### JDK环境配置

[链接地址](/posts/2018/09/04/jdk环境配置.html)

```shell
[root@bigdata-01 soft]# echo -e "# java\nexport JAVA_HOME=/opt/jdk\nexport PATH=\${PATH}:\${JAVA_HOME}/bin:\${JAVA_HOME}/jre/bin\nexport CLESSPATH=.:\${JAVA_HOME}/lib:\${JAVA_HOME}/jre/lib" > /etc/profile
[root@bigdata-01 soft]# source /etc/profile
```

### zookeeper 配置

```shell
[root@bigdata-01 soft]# echo  -e "\n# zookeeper\nexport ZK_HOME=/data/zookeeper\nexport PATH=\$PATH:\$ZK_HOME/bin" > /etc/profile
[root@bigdata-01 soft]# source /etc/profile
[root@bigdata-01 soft]# cp $ZK_HOME/conf/zoo_sample.cfg $ZK_HOME/conf/zoo.cfg
[root@bigdata-01 soft]# vim $ZK_HOME/conf/zoo.cfg
dataDir=/data/zookeeper/data
dataLogDir=/data/zookeeper/log
server.1=bigdata-01:2888:3888
server.2=bigdata-02:2888:3888
server.3=bigdata-03:2888:3888
```

分发并创建链接

```shell
[root@bigdata-01 soft]# echo 1 > /data/zookeeper/data/myid
[root@bigdata-02 soft]# echo 2 > /data/zookeeper/data/myid
[root@bigdata-03 soft]# echo 3 > /data/zookeeper/data/myid
[root@bigdata-* soft]# zkServer.sh start
```

### hadoop 配置

```shell
[root@bigdata-* soft]# echo -e "# hadoop\nexport HADOOP_HOME=/opt/hadoop\nexport HADOOP_PREFIX=\$HADOOP_HOME\nexport HADOOP_COMMON_HOME=\$HADOOP_PREFIX\nexport HADOOP_CONF_DIR=\$HADOOP_PREFIX/etc/hadoop\nexport HADOOP_HDFS_HOME=\$HADOOP_PREFIX\nexport HADOOP_MAPRED_HOME=\$HADOOP_PREFIX\nexport HADOOP_YARN_HOME=\$HADOOP_PREFIX\nexport PATH=\$PATH:\$HADOOP_HOME/bin:\$HADOOP_HOME/sbin" >> /etc/profile
[root@bigdata-* soft]# source /etc/profile
[root@bigdata-01 soft]# vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh
  export JAVA_HOME=/opt/jdk
  export HADOOP_SSH_OPTS="-p 22"
[root@bigdata-01 soft]# vim $HADOOP_HOME/etc/hadoop/mapred-env.sh
  export JAVA_HOME=/opt/jdk
[root@bigdata-01 soft]# vim $HADOOP_HOME/etc/hadoop/yarn-env.sh
  export JAVA_HOME=/opt/jdk
[root@bigdata-01 soft]# vim $HADOOP_HOME/etc/hadoop/core-site.xml
  <configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://bigdata-01:9000/</value>
    <description>NameNode URI, 192.168.1.100为服务器IP地址, 其实也可以使用主机名</description>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/data/hadoop/tmp</value>
  </property>
  <property>
    <name>hadoop.http.staticuser.user</name>
    <value>root</value>
  </property>
  <property>
    <name>ha.zookeeper.quorum</name>
    <value>bigdata-01:2181,bigdata-02:2181,bigdata-03:2181</value>
  </property>
  <property>
    <name>ha.zookeeper.session-timeout.ms</name>
    <value>10000</value>
  </property>
  <property>
    <name>fs.trash.checkpoint.interval</name>
    <value>1440</value>
    <discription>以分钟为单位的垃圾回收检查间隔。</discription>
  </property>
  <property>
    <name>hadoop.security.authentication</name>
    <value>simple</value>
    <discription>可以设置的值为 simple (无认证) 或者 kerberos（一种安全认证系统）</discription>
  </property>
  <property>
    <name>fs.trash.interval</name>
    <value>1440</value>
    <discription>以分钟为单位的垃圾回收时间, 垃圾站中数据超过此时间, 会被删除。如果是0, 垃圾回收机制关闭。</discription>
  </property>
  </configuration>
[root@bigdata-01 soft]# vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml
  <configuration>
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value>134217728</value>
  </property>
  <property>
    <name>dfs.permissions.enabled</name>
    <value>true</value>
    <description>true:权限检查, false：权限检查关闭,其他行为不变. 从一个参数值切换到另一个参数值不会改变模式、所有者或文件或目录组。</description>
  </property>
  
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/data/bigdata/hdfs/name</value>
    <discription>持久存储名字空间，事务日志的本地路径</discription>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/data/bigdata/hdfs/data</value>
    <discription>datanode存放数据的路径，单个节点单配，多个目录逗号分隔</discription>
  </property>
  <property>
    <name>dfs.datanode.max.transfer.threads</name>
    <value>16384</value>
    <discription>指定用于在DataNode间传输block数据的最大线程数</discription>
  </property>
  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>52428800</value>
    <description>Specifies the maximum amount of bandwidth that each datanode can utilize for the balancing purpose in term of the number of bytes per second.</description>
  </property>
  <property>
    <name>dfs.datanode.balance.max.concurrent.moves</name>
    <value>50</value>
    <description>增加DataNode上转移block的Xceiver的个数上限。</description>
  </property>

  <property>
    <name>dfs.nameservices</name>
    <value>ns1</value>
    <description>HDFS 命名服务的逻辑名称,可用户自己定义,比如 mycluster,注意,该名称将被基于 HDFS 的系统使用,比如 Hbase 等,此外,需要你想启用 HDFS Federation,可以通过该 参数指定多个逻辑名称,并用“,”分割。</description>
  </property>
  <property>
    <name>dfs.ha.namenodes.ns1</name>
    <value>nn1,nn2</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.ns1.nn1</name>
    <value>bigdata-01:8020</value>
    <discription>nn1的RPC通信地址, nn1所在地址</discription>
  </property>
  <property>
    <name>dfs.namenode.http-address.ns1.nn1</name>
    <value>bigdata-01:50070</value>
    <discription>nn1的http通信地址, 外部访问地址</discription>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.ns1.nn2</name>
    <value>bigdata-02:8020</value>
    <discription>nn2的RPC通信地址, nn2所在地址</discription>
  </property>
  <property>
    <name>dfs.namenode.http-address.ns1.nn2</name>
    <value>bigdata-02:50070</value>
    <discription>nn2的http通信地址, 外部访问地址</discription>
  </property>
  <property>
    <name>dfs.namenode.journalnode</name>
    <value>node1:8485;node2:8485;node3:8485</value>
    <discription>journalnode为了解决hadoop单点故障，给namenode做元数据同步的，奇数个,一般3个或5个</discription>
  </property>
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://${dfs.namenode.journalnode}/ns1</value>
    <description>指定NameNode的元数据在JournalNode日志上的存放位置(一般和zookeeper部署在一起)</description>
  </property>
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/data/hadoop/journal</value>
    <description>指定JournalNode在本地磁盘存放数据的位置</description>
  </property>
  <property>
    <name>dfs.client.failover.proxy.provider.ns1</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    <description>客户端通过代理访问namenode, 访问文件系统, HDFS 客户端与Active 节点通信的Java 类, 使用其确定Active 节点是否活跃</description>
  </property>
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence</value>
    <description>这是配置自动切换的方法, 有多种使用方法, 具体可以看官网, 在文末会给地址, 这里是远程登录杀死的方法, 这个参数的值可以有多种, 你也可以换成shell(/bin/true)试试, 也是可以的, 这个脚本do nothing 返回0</description>
  </property>
  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/root/.ssh/id_rsa</value>
    <description>这个是使用sshfence隔离机制时才需要配置ssh免登陆</description>
  </property>
  <property>
    <name>dfs.ha.fencing.ssh.connect-timeout</name>
    <value>30000</value>
    <description>配置sshfence隔离机制超时时间, 这个属性同上, 如果你是用脚本的方法切换, 这个应该是可以不配置的</description>
  </property>
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
    <description>开启自动故障转移, 如果你没有自动故障转移, 这个可以先不配</description>
  </property>
  </configuration>
[root@bigdata-01 soft]# vim $HADOOP_HOME/etc/hadoop/mapred-site.xml
  <configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.address</name>
    <value>bigdata-01:10020</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>bigdata-01:19888</value>
  </property>
  </configuration>
[root@bigdata-01 soft]# vim $HADOOP_HOME/etc/hadoop/yarn-site.xml
  <configuration>
  <property>
    <name>yarn.app.mapreduce.am.scheduler.connection.wait.interval-ms</name>
    <value>5000</value>
    <discription>schelduler失联等待连接时间</discription>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <name>yarn.resourcemanager.connect.retry-interval.ms</name>
    <value>5000</value>
    <description>How often to try connecting to the ResourceManager.</description>
  </property>
  <property>
    <name>yarn.resourcemanager.ha.enabled</name>
    <value>true</value>
    <discription>是否启用RM HA，默认为false（不启用）</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.ha.automatic-failover.enabled</name>
    <value>true</value>
    <discription>是否启用自动故障转移。默认情况下，在启用HA时，启用自动故障转移。</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.ha.automatic-failover.embedded</name>
    <value>true</value>
    <discription>启用内置的自动故障转移。默认情况下，在启用HA时，启用内置的自动故障转移。</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.cluster-id</name>
    <value>cluster1</value>
    <discription>集群的Id，elector使用该值确保RM不会做为其它集群的active。</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.ha.rm-ids</name>
    <value>rm1,rm2</value>
    <discription>RMs的逻辑id列表,rm管理资源器；一般配两个，一个起作用  其他备用；用逗号分隔,如:rm1,rm2 </discription>
  </property>
  <property>
    <name>yarn.resourcemanager.hostname.rm1</name>
    <value>bigdata-01</value>
    <discription>RM的节点1的hostname</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address.rm1</name>
    <value>${yarn.resourcemanager.hostname.rm1}:8030</value>
    <discription>RM对AM暴露的地址,AM通过地址想RM申请资源,释放资源等</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address.rm1</name>
    <value>${yarn.resourcemanager.hostname.rm1}:8031</value>
    <discription>RM对NM暴露地址,NM通过该地址向RM汇报心跳,领取任务等</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.address.rm1</name>
    <value>${yarn.resourcemanager.hostname.rm1}:8032</value>
    <discription>RM对客户端暴露的地址,客户端通过该地址向RM提交应用程序等</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address.rm1</name>
    <value>${yarn.resourcemanager.hostname.rm1}:8033</value>
    <discription>RM对管理员暴露的地址.管理员通过该地址向RM发送管理命令等</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address.rm1</name>
    <value>${yarn.resourcemanager.hostname.rm1}:8088</value>
    <discription>RM对外暴露的web http地址，用户可通过该地址在浏览器中查看集群信息</discription>
  </property>
  <property>
    <description>The https adddress of the RM web application.</description>
    <name>yarn.resourcemanager.webapp.https.address.rm1</name>
    <value>${yarn.resourcemanager.hostname.rm1}:8090</value>
  </property>
  <property>
    <name>yarn.resourcemanager.hostname.rm2</name>
    <value>bigdata-02</value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address.rm2</name>
    <value>${yarn.resourcemanager.hostname.rm2}:8030</value>
    </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address.rm2</name>
    <value>${yarn.resourcemanager.hostname.rm2}:8031</value>
  </property>
  <property>
    <name>yarn.resourcemanager.address.rm2</name>
    <value>${yarn.resourcemanager.hostname.rm2}:8032</value>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address.rm2</name>
    <value>${yarn.resourcemanager.hostname.rm2}:8033</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address.rm2</name>
    <value>${yarn.resourcemanager.hostname.rm2}:8088</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.https.address.rm2</name>
    <value>${yarn.resourcemanager.hostname.rm2}:8090</value>
  </property>
  <property>
    <name>yarn.resourcemanager.recovery.enabled</name>
    <value>true</value>
    <discription>默认值为false，也就是说resourcemanager挂了相应的正在运行的任务在rm恢复后不能重新启动</discription>
  </property>
  <property>
    <name>yarn.resourcemanager.store.class</name>
    <value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>
    <discription>状态存储的类</discription>
  </property>
  <property>
    <name>ha.zookeeper.quorum</name>
    <value>node1:2181,node2:2181,node3:2181</value>
  </property>
  <property>
    <name>yarn.resourcemanager.zk-address</name>
    <value>${ha.zookeeper.quorum}</value>
    <discription>ZooKeeper服务器的地址（主机：端口号），既用于状态存储也用于内嵌的leader-election。</discription>
  </property>
  <property>
    <name>yarn.nodemanager.address</name>
    <value>${yarn.nodemanager.hostname}:8041</value>
    <discription>The address of the container manager in the NM.</discription>
  </property>
  <property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
  </property>
    <property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>106800</value>
  </property>
  </configuration>
[root@bigdata-01 soft]# vim $HADOOP_HOME/etc/hadoop/slaves
  bigdata-01
  bigdata-02
  bigdata-03
```

分发并创建链接

```shell
[root@bigdata-* soft]# $HADOOP_HOME/sbin/hadoop-daemon.sh start journalnode
[root@bigdata-01 soft]# hdfs namenode -format
[root@bigdata-01 soft]# hadoop-daemon.sh start namenode
[root@bigdata-02 soft]# hdfs namenode -bootstrapStandby
[root@bigdata-02 soft]# hadoop-daemon.sh start namenode
[root@bigdata-01 soft]# hdfs zkfc -formatZK
[root@bigdata-01 soft]# hadoop-daemon.sh start zkfc
[root@bigdata-01 soft]# start-dfs.sh
[root@bigdata-01 soft]# start-yarn.sh
[root@bigdata-03 soft]# yarn-daemon.sh start resourcemanager
```

验证高可用

```shell
[root@bigdata-01 soft]# jps
16704 JournalNode
16288 NameNode
16433 DataNode
23993 QuorumPeerMain
17241 NodeManager
18621 Jps
16942 DFSZKFailoverController
[root@bigdata-01 soft]# kill -9 16288
```

### spark 配置

scala

```shell
[root@bigdata-* soft]# echo -e "\n# scala\nexport SCALA_HOME=/opt/scala\nexport PATH=$PATH:\$SCALA_HOME/bin" >> /etc/profile
[root@bigdata-* soft]# source /etc/profile
[root@bigdata-* soft]# echo  -e "\n# spark\nexport SPARK_HOME=/opt/spark\nexport PATH=\$SPARK_HOME/bin:\$PATH" >> /etc/profile
[root@bigdata-* soft]# source /etc/profile
[root@bigdata-01 soft]# cp $SPARK_HOME/conf/spark-env.sh{.template,}
[root@bigdata-01 soft]# vim $SPARK_HOME/conf/spark-env.sh
  export SPARK_LOCAL_IP="192.168.1.101"           # 从节点改为自己的IP（或127.0.0.1 ），或者注掉
  export SPARK_MASTER_IP="192.168.1.101"         
  export JAVA_HOME=/opt/jdk
  export SPARK_PID_DIR=/data/hadoop/tmp

  # export SPARK_WORKER_MEMORY=58g # 设置内存，本节点可以调用的内存
  export SPARK_MASTER_PORT=7077
  export SPARK_WORKER_INSTANCES=1
  export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
  export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native
  export SPARK_HISTORY_OPTS="-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=3 -Dspark.history.fs.logDirectory=hdfs://mycluster/directory"
  # 限制程序申请资源最大核数，本节点可以调用的cpu核数
  export SPARK_MASTER_OPTS="-Dspark.deploy.defaultCores=16"
  export SPARK_SSH_OPTS="-p 22 -o StrictHostKeyChecking=no $SPARK_SSH_OPTS"
[root@bigdata-01 soft]# cp $SPARK_HOME/conf/spark-defaults.conf{.template,}
[root@bigdata-01 soft]# vim $SPARK_HOME/conf/spark-defaults.conf
  #添加
  spark.serializer		org.apache.spark.serializer.KryoSerializer
  spark.eventLog.enabled	true
  spark.eventLog.dir		hdfs://mycluster/directory
  spark.local.dir			/data/spark/tmp
[root@bigdata-01 soft]# cp $SPARK_HOME/conf/slaves{.template,}
[root@bigdata-01 soft]# vim $SPARK_HOME/conf/slaves
  bigdata-01
  bigdata-02
  bigdata-03
分发、创建软连接并修改$SPARK_HOME/conf/spark-env.sh中的SPARK_LOCAL_IP参数
$SPARK_HOME/sbin/start-all.sh
```

### hive

#### mysql(元数据)

安装

```shell
echo  -e "\n# hive\nexport HIVE_HOME=/opt/hive\nexport PATH=\$PATH:\$HIVE_HOME/bin" >> /etc/profile
source /etc/profile
hdfs dfs -mkdir /tmp
hdfs dfs -mkdir /user
hdfs dfs -mkdir /user/hive
hdfs dfs -mkdir /user/hive/warehouse
hadoop fs -chmod g+w /tmp
hadoop fs -chmod g+w /user/hive/warehouse
cp $HIVE_HOME/conf/hive-default.xml.template $HIVE_HOME/conf/hive-site.xml
vim $HIVE_HOME/conf/hive-site.xml
  <configuration>
    <property>
      <name>hive.metastore.uris</name>
      <value>thrift://lvmama:9083</value>
      <description>该参数指定了 Hive 的数据存储目录，默认位置在 HDFS 上面的 /user/hive/warehouse 路径下。</description>
    </property>
    <property>
      <name>hive.metastore.warehouse.dir</name>
      <value>/hive</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionURL</name>
      <value>jdbc:mysql://lvmama:3306/hive?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=utf8</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionUserName</name>
      <value>hive</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionPassword</name>
      <value>hive</value>
    </property>
  </configuration>
schematool -initSchema -dbType mysql
```
